{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux-okIrPXWEj",
        "outputId": "9ad298ed-2446-449c-d6b7-fefde0aa8c0f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import openpyxl\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import keras_tuner\n",
        "from keras_tuner import RandomSearch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from openpyxl import load_workbook\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBlD9UXkXypM",
        "outputId": "54cb3a00-0e0f-47f2-c511-03d05b70f237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data in sheet 'location_1':\n",
            "      idates  imonths  iyears  observeddata_77.5_8.5  meanmodeldata_77.5_8.5  \\\n",
            "0          1        1    2007                   4.08                    3.93   \n",
            "1          2        1    2007                   4.63                    5.18   \n",
            "2          3        1    2007                   4.84                    5.21   \n",
            "3          4        1    2007                   4.64                    4.89   \n",
            "4          5        1    2007                   4.74                    5.17   \n",
            "...      ...      ...     ...                    ...                     ...   \n",
            "4630      27       12    2019                   3.87                    4.07   \n",
            "4631      28       12    2019                   4.49                    4.73   \n",
            "4632      29       12    2019                   3.89                    4.08   \n",
            "4633      30       12    2019                   4.22                    4.48   \n",
            "4634      31       12    2019                   3.95                    4.20   \n",
            "\n",
            "      stdmodeldata_77.5_8.5  errordata_77.5_8.5  \n",
            "0                      0.09                0.15  \n",
            "1                      0.08               -0.55  \n",
            "2                      0.10               -0.37  \n",
            "3                      0.12               -0.25  \n",
            "4                      0.09               -0.43  \n",
            "...                     ...                 ...  \n",
            "4630                   0.17               -0.20  \n",
            "4631                   0.22               -0.24  \n",
            "4632                   0.16               -0.19  \n",
            "4633                   0.13               -0.26  \n",
            "4634                   0.15               -0.25  \n",
            "\n",
            "[4635 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "excel_file = pd.ExcelFile(\"pet_btech_data_location.xlsx\")\n",
        "for sheet_name in excel_file.sheet_names:\n",
        "    if sheet_name == \"location_1\":\n",
        "        sheet_data = excel_file.parse(sheet_name)\n",
        "        print(\"Data in sheet 'location_1':\")\n",
        "        print(sheet_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QaymO62ttlai"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_lstm_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Int('first_hidden_layer_units', min_value=64, max_value=256, step=32),\n",
        "                   activation='relu',\n",
        "                   input_shape=(1, 3),\n",
        "                   return_sequences=True))\n",
        "    \n",
        "    model.add(LSTM(units=hp.Int('second_hidden_layer_units', min_value=32, max_value=128, step=16),\n",
        "                   activation='relu',\n",
        "                   return_sequences=True))\n",
        "    \n",
        "    model.add(LSTM(units=hp.Int('third_hidden_layer_units', min_value=16, max_value=64, step=8),\n",
        "                   activation='relu',\n",
        "                   return_sequences=True))\n",
        "    \n",
        "    model.add(Flatten())  # Flatten before Dense layer\n",
        "    \n",
        "    model.add(Dense(units=hp.Int('dense_layer_units', min_value=8, max_value=64, step=8), activation='relu'))\n",
        "    \n",
        "    model.add(Dense(1))\n",
        "    \n",
        "    optimizer = Adam(learning_rate=hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5]))\n",
        "    \n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yujbHbaFwzP6"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(X_train, Y_train, X_test, Y_test, sheet_name, split_num):\n",
        "\n",
        "   #Creating a separate directory for each split\n",
        "    split_directory = os.path.join('RandomSearch', sheet_name, f'split_{split_num}')\n",
        "    os.makedirs(split_directory, exist_ok=True)\n",
        "\n",
        "    tuner = RandomSearch(\n",
        "        create_lstm_model,\n",
        "        objective= \"mean_squared_error\",\n",
        "        max_trials=50,\n",
        "        executions_per_trial=1,\n",
        "        directory=split_directory,  # Directory to store results\n",
        "        project_name = 'BTP',\n",
        "        overwrite=False\n",
        "    )\n",
        "    results=[]\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=False)\n",
        "\n",
        "    for train_index, val_index in kf.split(X_train):\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        Y_train_fold, Y_val_fold = Y_train[train_index], Y_train[val_index]\n",
        "      \n",
        "        tuner.search(X_train_fold, Y_train_fold, validation_data=(X_val_fold, Y_val_fold), epochs=100, batch_size=32)\n",
        "        \n",
        "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "    best_model = tuner.hypermodel.build(best_hps)\n",
        "    print(best_hps.get_config())\n",
        "    \n",
        "    history = best_model.fit(X_train, Y_train, epochs=101, validation_data=(X_val_fold, Y_val_fold), batch_size=32, verbose=1)\n",
        "\n",
        "    Y_pred = best_model.predict(X_test)\n",
        "    Y_pred = Y_pred.flatten()\n",
        "\n",
        "        # Calculating RMSE, MSE, MAE, and bias for \"model_trained_observed_value\"\n",
        "    rmse = np.sqrt(mean_squared_error(Y_test,Y_pred))\n",
        "    mse = mean_squared_error(Y_test,Y_pred)\n",
        "    mae = mean_absolute_error(Y_test,Y_pred)\n",
        "    bias = np.mean(Y_test- Y_pred)\n",
        "\n",
        "    results.append({\n",
        "            'RMSE': rmse,\n",
        "            'MSE': mse,\n",
        "            'MAE': mae,\n",
        "            'Bias': bias\n",
        "        })\n",
        "\n",
        "    return results, Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQbX1Iimol5E",
        "outputId": "62c8e033-a96e-4700-bef9-ed7ff357c0d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3.93 5.18 5.21 ... 5.96 6.88 7.07]\n",
            "[4.08 4.63 4.84 ... 5.38 5.98 5.96]\n",
            "length of X_test = 1158\n",
            "length of X_train = 3477\n",
            "length of Y_test = 1158\n",
            "length of Y_train = 3477\n",
            "sheet name location_1 : num_split 0 :  X_train [[[6.88e+00 8.00e-02 7.80e+01]]\n",
            "\n",
            " [[6.72e+00 1.00e-01 7.90e+01]]\n",
            "\n",
            " [[6.07e+00 9.00e-02 8.00e+01]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[4.08e+00 1.60e-01 3.63e+02]]\n",
            "\n",
            " [[4.48e+00 1.30e-01 3.64e+02]]\n",
            "\n",
            " [[4.20e+00 1.50e-01 3.65e+02]]]\n",
            "sheet name location_1 : num_split 0 :  X_test [[[ 3.93  0.09  1.  ]]\n",
            "\n",
            " [[ 5.18  0.08  2.  ]]\n",
            "\n",
            " [[ 5.21  0.1   3.  ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 5.96  0.09 75.  ]]\n",
            "\n",
            " [[ 6.88  0.08 76.  ]]\n",
            "\n",
            " [[ 7.07  0.11 77.  ]]]\n",
            "Reloading Tuner from RandomSearch\\location_1\\split_0\\BTP\\tuner0.json\n",
            "{'space': [{'class_name': 'Int', 'config': {'name': 'first_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 64, 'max_value': 256, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'second_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'third_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 8, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'dense_layer_units', 'default': None, 'conditions': [], 'min_value': 8, 'max_value': 64, 'step': 8, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.001, 'conditions': [], 'values': [0.001, 0.0001, 1e-05], 'ordered': True}}], 'values': {'first_hidden_layer_units': 128, 'second_hidden_layer_units': 32, 'third_hidden_layer_units': 16, 'dense_layer_units': 40, 'learning_rate': 0.0001}}\n",
            "Epoch 1/101\n",
            "109/109 [==============================] - 8s 18ms/step - loss: 19.2656 - mean_squared_error: 19.2656 - val_loss: 12.6994 - val_mean_squared_error: 12.6994\n",
            "Epoch 2/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 8.9154 - mean_squared_error: 8.9154 - val_loss: 5.4474 - val_mean_squared_error: 5.4474\n",
            "Epoch 3/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 2.7425 - mean_squared_error: 2.7425 - val_loss: 1.2712 - val_mean_squared_error: 1.2712\n",
            "Epoch 4/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 1.1938 - mean_squared_error: 1.1938 - val_loss: 0.8768 - val_mean_squared_error: 0.8768\n",
            "Epoch 5/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 0.8590 - mean_squared_error: 0.8590 - val_loss: 0.6727 - val_mean_squared_error: 0.6727\n",
            "Epoch 6/101\n",
            "109/109 [==============================] - 1s 9ms/step - loss: 0.6491 - mean_squared_error: 0.6491 - val_loss: 0.6196 - val_mean_squared_error: 0.6196\n",
            "Epoch 7/101\n",
            "109/109 [==============================] - 1s 9ms/step - loss: 0.4961 - mean_squared_error: 0.4961 - val_loss: 0.4011 - val_mean_squared_error: 0.4011\n",
            "Epoch 8/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 0.4134 - mean_squared_error: 0.4134 - val_loss: 0.3428 - val_mean_squared_error: 0.3428\n",
            "Epoch 9/101\n",
            "109/109 [==============================] - 1s 9ms/step - loss: 0.3592 - mean_squared_error: 0.3592 - val_loss: 0.3052 - val_mean_squared_error: 0.3052\n",
            "Epoch 10/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 0.3341 - mean_squared_error: 0.3341 - val_loss: 0.3011 - val_mean_squared_error: 0.3011\n",
            "Epoch 11/101\n",
            "109/109 [==============================] - 1s 12ms/step - loss: 0.3083 - mean_squared_error: 0.3083 - val_loss: 0.2486 - val_mean_squared_error: 0.2486\n",
            "Epoch 12/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2996 - mean_squared_error: 0.2996 - val_loss: 0.2202 - val_mean_squared_error: 0.2202\n",
            "Epoch 13/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2859 - mean_squared_error: 0.2859 - val_loss: 0.2420 - val_mean_squared_error: 0.2420\n",
            "Epoch 14/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2769 - mean_squared_error: 0.2769 - val_loss: 0.1903 - val_mean_squared_error: 0.1903\n",
            "Epoch 15/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2698 - mean_squared_error: 0.2698 - val_loss: 0.2427 - val_mean_squared_error: 0.2427\n",
            "Epoch 16/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2658 - mean_squared_error: 0.2658 - val_loss: 0.3154 - val_mean_squared_error: 0.3154\n",
            "Epoch 17/101\n",
            "109/109 [==============================] - 2s 15ms/step - loss: 0.2665 - mean_squared_error: 0.2665 - val_loss: 0.2557 - val_mean_squared_error: 0.2557\n",
            "Epoch 18/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2663 - mean_squared_error: 0.2663 - val_loss: 0.2483 - val_mean_squared_error: 0.2483\n",
            "Epoch 19/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2610 - mean_squared_error: 0.2610 - val_loss: 0.2063 - val_mean_squared_error: 0.2063\n",
            "Epoch 20/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2568 - mean_squared_error: 0.2568 - val_loss: 0.2815 - val_mean_squared_error: 0.2815\n",
            "Epoch 21/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2580 - mean_squared_error: 0.2580 - val_loss: 0.2925 - val_mean_squared_error: 0.2925\n",
            "Epoch 22/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2540 - mean_squared_error: 0.2540 - val_loss: 0.3709 - val_mean_squared_error: 0.3709\n",
            "Epoch 23/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2657 - mean_squared_error: 0.2657 - val_loss: 0.2269 - val_mean_squared_error: 0.2269\n",
            "Epoch 24/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2605 - mean_squared_error: 0.2605 - val_loss: 0.1998 - val_mean_squared_error: 0.1998\n",
            "Epoch 25/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2612 - mean_squared_error: 0.2612 - val_loss: 0.2086 - val_mean_squared_error: 0.2086\n",
            "Epoch 26/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2549 - mean_squared_error: 0.2549 - val_loss: 0.2581 - val_mean_squared_error: 0.2581\n",
            "Epoch 27/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2562 - mean_squared_error: 0.2562 - val_loss: 0.2016 - val_mean_squared_error: 0.2016\n",
            "Epoch 28/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2535 - mean_squared_error: 0.2535 - val_loss: 0.1889 - val_mean_squared_error: 0.1889\n",
            "Epoch 29/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2535 - mean_squared_error: 0.2535 - val_loss: 0.2261 - val_mean_squared_error: 0.2261\n",
            "Epoch 30/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2590 - mean_squared_error: 0.2590 - val_loss: 0.2206 - val_mean_squared_error: 0.2206\n",
            "Epoch 31/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2525 - mean_squared_error: 0.2525 - val_loss: 0.2108 - val_mean_squared_error: 0.2108\n",
            "Epoch 32/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2577 - mean_squared_error: 0.2577 - val_loss: 0.1907 - val_mean_squared_error: 0.1907\n",
            "Epoch 33/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2536 - mean_squared_error: 0.2536 - val_loss: 0.2906 - val_mean_squared_error: 0.2906\n",
            "Epoch 34/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2559 - mean_squared_error: 0.2559 - val_loss: 0.2214 - val_mean_squared_error: 0.2214\n",
            "Epoch 35/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2549 - mean_squared_error: 0.2549 - val_loss: 0.2288 - val_mean_squared_error: 0.2288\n",
            "Epoch 36/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2469 - mean_squared_error: 0.2469 - val_loss: 0.2810 - val_mean_squared_error: 0.2810\n",
            "Epoch 37/101\n",
            "109/109 [==============================] - 2s 15ms/step - loss: 0.2524 - mean_squared_error: 0.2524 - val_loss: 0.2111 - val_mean_squared_error: 0.2111\n",
            "Epoch 38/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2482 - mean_squared_error: 0.2482 - val_loss: 0.2102 - val_mean_squared_error: 0.2102\n",
            "Epoch 39/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2496 - mean_squared_error: 0.2496 - val_loss: 0.2273 - val_mean_squared_error: 0.2273\n",
            "Epoch 40/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2492 - mean_squared_error: 0.2492 - val_loss: 0.2877 - val_mean_squared_error: 0.2877\n",
            "Epoch 41/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2520 - mean_squared_error: 0.2520 - val_loss: 0.2321 - val_mean_squared_error: 0.2321\n",
            "Epoch 42/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2512 - mean_squared_error: 0.2512 - val_loss: 0.2644 - val_mean_squared_error: 0.2644\n",
            "Epoch 43/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2463 - mean_squared_error: 0.2463 - val_loss: 0.3122 - val_mean_squared_error: 0.3122\n",
            "Epoch 44/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2516 - mean_squared_error: 0.2516 - val_loss: 0.2051 - val_mean_squared_error: 0.2051\n",
            "Epoch 45/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2481 - mean_squared_error: 0.2481 - val_loss: 0.2276 - val_mean_squared_error: 0.2276\n",
            "Epoch 46/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2540 - mean_squared_error: 0.2540 - val_loss: 0.2822 - val_mean_squared_error: 0.2822\n",
            "Epoch 47/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2553 - mean_squared_error: 0.2553 - val_loss: 0.1874 - val_mean_squared_error: 0.1874\n",
            "Epoch 48/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2478 - mean_squared_error: 0.2478 - val_loss: 0.2915 - val_mean_squared_error: 0.2915\n",
            "Epoch 49/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2472 - mean_squared_error: 0.2472 - val_loss: 0.3235 - val_mean_squared_error: 0.3235\n",
            "Epoch 50/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2492 - mean_squared_error: 0.2492 - val_loss: 0.1893 - val_mean_squared_error: 0.1893\n",
            "Epoch 51/101\n",
            "109/109 [==============================] - 1s 14ms/step - loss: 0.2512 - mean_squared_error: 0.2512 - val_loss: 0.2301 - val_mean_squared_error: 0.2301\n",
            "Epoch 52/101\n",
            "109/109 [==============================] - 1s 12ms/step - loss: 0.2630 - mean_squared_error: 0.2630 - val_loss: 0.2268 - val_mean_squared_error: 0.2268\n",
            "Epoch 53/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2442 - mean_squared_error: 0.2442 - val_loss: 0.1880 - val_mean_squared_error: 0.1880\n",
            "Epoch 54/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2503 - mean_squared_error: 0.2503 - val_loss: 0.1989 - val_mean_squared_error: 0.1989\n",
            "Epoch 55/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2447 - mean_squared_error: 0.2447 - val_loss: 0.2162 - val_mean_squared_error: 0.2162\n",
            "Epoch 56/101\n",
            "109/109 [==============================] - 2s 14ms/step - loss: 0.2444 - mean_squared_error: 0.2444 - val_loss: 0.1855 - val_mean_squared_error: 0.1855\n",
            "Epoch 57/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2603 - mean_squared_error: 0.2603 - val_loss: 0.2392 - val_mean_squared_error: 0.2392\n",
            "Epoch 58/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2459 - mean_squared_error: 0.2459 - val_loss: 0.2717 - val_mean_squared_error: 0.2717\n",
            "Epoch 59/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2524 - mean_squared_error: 0.2524 - val_loss: 0.2437 - val_mean_squared_error: 0.2437\n",
            "Epoch 60/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2466 - mean_squared_error: 0.2466 - val_loss: 0.2473 - val_mean_squared_error: 0.2473\n",
            "Epoch 61/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2437 - mean_squared_error: 0.2437 - val_loss: 0.2299 - val_mean_squared_error: 0.2299\n",
            "Epoch 62/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2465 - mean_squared_error: 0.2465 - val_loss: 0.2199 - val_mean_squared_error: 0.2199\n",
            "Epoch 63/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2522 - mean_squared_error: 0.2522 - val_loss: 0.2073 - val_mean_squared_error: 0.2073\n",
            "Epoch 64/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2470 - mean_squared_error: 0.2470 - val_loss: 0.2087 - val_mean_squared_error: 0.2087\n",
            "Epoch 65/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2479 - mean_squared_error: 0.2479 - val_loss: 0.2186 - val_mean_squared_error: 0.2186\n",
            "Epoch 66/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2466 - mean_squared_error: 0.2466 - val_loss: 0.2562 - val_mean_squared_error: 0.2562\n",
            "Epoch 67/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2485 - mean_squared_error: 0.2485 - val_loss: 0.2095 - val_mean_squared_error: 0.2095\n",
            "Epoch 68/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2450 - mean_squared_error: 0.2450 - val_loss: 0.2023 - val_mean_squared_error: 0.2023\n",
            "Epoch 69/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2445 - mean_squared_error: 0.2445 - val_loss: 0.2315 - val_mean_squared_error: 0.2315\n",
            "Epoch 70/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2471 - mean_squared_error: 0.2471 - val_loss: 0.1998 - val_mean_squared_error: 0.1998\n",
            "Epoch 71/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2432 - mean_squared_error: 0.2432 - val_loss: 0.2340 - val_mean_squared_error: 0.2340\n",
            "Epoch 72/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2432 - mean_squared_error: 0.2432 - val_loss: 0.2158 - val_mean_squared_error: 0.2158\n",
            "Epoch 73/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2481 - mean_squared_error: 0.2481 - val_loss: 0.1965 - val_mean_squared_error: 0.1965\n",
            "Epoch 74/101\n",
            "109/109 [==============================] - 2s 16ms/step - loss: 0.2486 - mean_squared_error: 0.2486 - val_loss: 0.2335 - val_mean_squared_error: 0.2335\n",
            "Epoch 75/101\n",
            "109/109 [==============================] - 1s 9ms/step - loss: 0.2397 - mean_squared_error: 0.2397 - val_loss: 0.1977 - val_mean_squared_error: 0.1977\n",
            "Epoch 76/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2434 - mean_squared_error: 0.2434 - val_loss: 0.2397 - val_mean_squared_error: 0.2397\n",
            "Epoch 77/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2464 - mean_squared_error: 0.2464 - val_loss: 0.2452 - val_mean_squared_error: 0.2452\n",
            "Epoch 78/101\n",
            "109/109 [==============================] - 1s 12ms/step - loss: 0.2444 - mean_squared_error: 0.2444 - val_loss: 0.2690 - val_mean_squared_error: 0.2690\n",
            "Epoch 79/101\n",
            "109/109 [==============================] - 2s 14ms/step - loss: 0.2429 - mean_squared_error: 0.2429 - val_loss: 0.2126 - val_mean_squared_error: 0.2126\n",
            "Epoch 80/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2440 - mean_squared_error: 0.2440 - val_loss: 0.2627 - val_mean_squared_error: 0.2627\n",
            "Epoch 81/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 0.2412 - mean_squared_error: 0.2412 - val_loss: 0.2180 - val_mean_squared_error: 0.2180\n",
            "Epoch 82/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 0.2437 - mean_squared_error: 0.2437 - val_loss: 0.2417 - val_mean_squared_error: 0.2417\n",
            "Epoch 83/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 0.2424 - mean_squared_error: 0.2424 - val_loss: 0.2115 - val_mean_squared_error: 0.2115\n",
            "Epoch 84/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 0.2427 - mean_squared_error: 0.2427 - val_loss: 0.2865 - val_mean_squared_error: 0.2865\n",
            "Epoch 85/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 0.2466 - mean_squared_error: 0.2466 - val_loss: 0.1833 - val_mean_squared_error: 0.1833\n",
            "Epoch 86/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2455 - mean_squared_error: 0.2455 - val_loss: 0.1973 - val_mean_squared_error: 0.1973\n",
            "Epoch 87/101\n",
            "109/109 [==============================] - 2s 14ms/step - loss: 0.2403 - mean_squared_error: 0.2403 - val_loss: 0.2143 - val_mean_squared_error: 0.2143\n",
            "Epoch 88/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 0.2418 - mean_squared_error: 0.2418 - val_loss: 0.2850 - val_mean_squared_error: 0.2850\n",
            "Epoch 89/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2456 - mean_squared_error: 0.2456 - val_loss: 0.2048 - val_mean_squared_error: 0.2048\n",
            "Epoch 90/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 0.2513 - mean_squared_error: 0.2513 - val_loss: 0.2165 - val_mean_squared_error: 0.2165\n",
            "Epoch 91/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2411 - mean_squared_error: 0.2411 - val_loss: 0.2814 - val_mean_squared_error: 0.2814\n",
            "Epoch 92/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2427 - mean_squared_error: 0.2427 - val_loss: 0.2149 - val_mean_squared_error: 0.2149\n",
            "Epoch 93/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2418 - mean_squared_error: 0.2418 - val_loss: 0.2528 - val_mean_squared_error: 0.2528\n",
            "Epoch 94/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2439 - mean_squared_error: 0.2439 - val_loss: 0.1963 - val_mean_squared_error: 0.1963\n",
            "Epoch 95/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2444 - mean_squared_error: 0.2444 - val_loss: 0.2068 - val_mean_squared_error: 0.2068\n",
            "Epoch 96/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2437 - mean_squared_error: 0.2437 - val_loss: 0.2025 - val_mean_squared_error: 0.2025\n",
            "Epoch 97/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2407 - mean_squared_error: 0.2407 - val_loss: 0.2049 - val_mean_squared_error: 0.2049\n",
            "Epoch 98/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2433 - mean_squared_error: 0.2433 - val_loss: 0.1828 - val_mean_squared_error: 0.1828\n",
            "Epoch 99/101\n",
            "109/109 [==============================] - 1s 10ms/step - loss: 0.2460 - mean_squared_error: 0.2460 - val_loss: 0.2235 - val_mean_squared_error: 0.2235\n",
            "Epoch 100/101\n",
            "109/109 [==============================] - 1s 12ms/step - loss: 0.2467 - mean_squared_error: 0.2467 - val_loss: 0.1773 - val_mean_squared_error: 0.1773\n",
            "Epoch 101/101\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.2403 - mean_squared_error: 0.2403 - val_loss: 0.2264 - val_mean_squared_error: 0.2264\n",
            "37/37 [==============================] - 1s 4ms/step\n",
            "Results for location_1 - Split 1\n",
            "RMSE: 0.7555\n",
            "MSE: 0.5707\n",
            "MAE: 0.5619\n",
            "Bias: -0.4673\n",
            "\n",
            "[6.88 6.72 6.07 ... 5.99 5.87 4.67]\n",
            "[5.9  5.46 5.36 ... 5.01 5.21 3.76]\n",
            "length of X_test = 1158\n",
            "length of X_train = 3477\n",
            "length of Y_test = 1158\n",
            "length of Y_train = 3477\n",
            "sheet name location_1 : num_split 1 :  X_train [[[3.93e+00 9.00e-02 1.00e+00]]\n",
            "\n",
            " [[5.18e+00 8.00e-02 2.00e+00]]\n",
            "\n",
            " [[5.21e+00 1.00e-01 3.00e+00]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[4.08e+00 1.60e-01 3.63e+02]]\n",
            "\n",
            " [[4.48e+00 1.30e-01 3.64e+02]]\n",
            "\n",
            " [[4.20e+00 1.50e-01 3.65e+02]]]\n",
            "sheet name location_1 : num_split 1 :  X_test [[[6.88e+00 8.00e-02 7.80e+01]]\n",
            "\n",
            " [[6.72e+00 1.00e-01 7.90e+01]]\n",
            "\n",
            " [[6.07e+00 9.00e-02 8.00e+01]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[5.99e+00 2.20e-01 1.95e+02]]\n",
            "\n",
            " [[5.87e+00 3.30e-01 1.96e+02]]\n",
            "\n",
            " [[4.67e+00 2.60e-01 1.97e+02]]]\n",
            "Reloading Tuner from RandomSearch\\location_1\\split_1\\BTP\\tuner0.json\n",
            "{'space': [{'class_name': 'Int', 'config': {'name': 'first_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 64, 'max_value': 256, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'second_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'third_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 8, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'dense_layer_units', 'default': None, 'conditions': [], 'min_value': 8, 'max_value': 64, 'step': 8, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.001, 'conditions': [], 'values': [0.001, 0.0001, 1e-05], 'ordered': True}}], 'values': {'first_hidden_layer_units': 256, 'second_hidden_layer_units': 80, 'third_hidden_layer_units': 16, 'dense_layer_units': 56, 'learning_rate': 0.0001}}\n",
            "Epoch 1/101\n",
            "109/109 [==============================] - 8s 25ms/step - loss: 16.8871 - mean_squared_error: 16.8871 - val_loss: 8.0354 - val_mean_squared_error: 8.0354\n",
            "Epoch 2/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 4.2419 - mean_squared_error: 4.2419 - val_loss: 1.4734 - val_mean_squared_error: 1.4734\n",
            "Epoch 3/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 1.4596 - mean_squared_error: 1.4596 - val_loss: 0.9598 - val_mean_squared_error: 0.9598\n",
            "Epoch 4/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.9797 - mean_squared_error: 0.9797 - val_loss: 0.7148 - val_mean_squared_error: 0.7148\n",
            "Epoch 5/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.7152 - mean_squared_error: 0.7152 - val_loss: 0.6257 - val_mean_squared_error: 0.6257\n",
            "Epoch 6/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.5771 - mean_squared_error: 0.5771 - val_loss: 0.4436 - val_mean_squared_error: 0.4436\n",
            "Epoch 7/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.4695 - mean_squared_error: 0.4695 - val_loss: 0.3906 - val_mean_squared_error: 0.3906\n",
            "Epoch 8/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.4325 - mean_squared_error: 0.4325 - val_loss: 0.3136 - val_mean_squared_error: 0.3136\n",
            "Epoch 9/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.4022 - mean_squared_error: 0.4022 - val_loss: 0.4579 - val_mean_squared_error: 0.4579\n",
            "Epoch 10/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3739 - mean_squared_error: 0.3739 - val_loss: 0.2728 - val_mean_squared_error: 0.2728\n",
            "Epoch 11/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3571 - mean_squared_error: 0.3571 - val_loss: 0.2766 - val_mean_squared_error: 0.2766\n",
            "Epoch 12/101\n",
            "109/109 [==============================] - 2s 21ms/step - loss: 0.3566 - mean_squared_error: 0.3566 - val_loss: 0.2598 - val_mean_squared_error: 0.2598\n",
            "Epoch 13/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3578 - mean_squared_error: 0.3578 - val_loss: 0.2571 - val_mean_squared_error: 0.2571\n",
            "Epoch 14/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3698 - mean_squared_error: 0.3698 - val_loss: 0.2386 - val_mean_squared_error: 0.2386\n",
            "Epoch 15/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3435 - mean_squared_error: 0.3435 - val_loss: 0.2121 - val_mean_squared_error: 0.2121\n",
            "Epoch 16/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3419 - mean_squared_error: 0.3419 - val_loss: 0.4285 - val_mean_squared_error: 0.4285\n",
            "Epoch 17/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3367 - mean_squared_error: 0.3367 - val_loss: 0.4227 - val_mean_squared_error: 0.4227\n",
            "Epoch 18/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3358 - mean_squared_error: 0.3358 - val_loss: 0.3179 - val_mean_squared_error: 0.3179\n",
            "Epoch 19/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3336 - mean_squared_error: 0.3336 - val_loss: 0.2608 - val_mean_squared_error: 0.2608\n",
            "Epoch 20/101\n",
            "109/109 [==============================] - 2s 22ms/step - loss: 0.3368 - mean_squared_error: 0.3368 - val_loss: 0.2241 - val_mean_squared_error: 0.2241\n",
            "Epoch 21/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3385 - mean_squared_error: 0.3385 - val_loss: 0.2718 - val_mean_squared_error: 0.2718\n",
            "Epoch 22/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3285 - mean_squared_error: 0.3285 - val_loss: 0.2897 - val_mean_squared_error: 0.2897\n",
            "Epoch 23/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3341 - mean_squared_error: 0.3341 - val_loss: 0.2511 - val_mean_squared_error: 0.2511\n",
            "Epoch 24/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3312 - mean_squared_error: 0.3312 - val_loss: 0.2536 - val_mean_squared_error: 0.2536\n",
            "Epoch 25/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3281 - mean_squared_error: 0.3281 - val_loss: 0.2979 - val_mean_squared_error: 0.2979\n",
            "Epoch 26/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3343 - mean_squared_error: 0.3343 - val_loss: 0.2381 - val_mean_squared_error: 0.2381\n",
            "Epoch 27/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3314 - mean_squared_error: 0.3314 - val_loss: 0.4006 - val_mean_squared_error: 0.4006\n",
            "Epoch 28/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.2972 - val_mean_squared_error: 0.2972\n",
            "Epoch 29/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3292 - mean_squared_error: 0.3292 - val_loss: 0.2849 - val_mean_squared_error: 0.2849\n",
            "Epoch 30/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3248 - mean_squared_error: 0.3248 - val_loss: 0.2296 - val_mean_squared_error: 0.2296\n",
            "Epoch 31/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3279 - mean_squared_error: 0.3279 - val_loss: 0.2280 - val_mean_squared_error: 0.2280\n",
            "Epoch 32/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3283 - mean_squared_error: 0.3283 - val_loss: 0.2516 - val_mean_squared_error: 0.2516\n",
            "Epoch 33/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3253 - mean_squared_error: 0.3253 - val_loss: 0.2145 - val_mean_squared_error: 0.2145\n",
            "Epoch 34/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3240 - mean_squared_error: 0.3240 - val_loss: 0.2136 - val_mean_squared_error: 0.2136\n",
            "Epoch 35/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3222 - mean_squared_error: 0.3222 - val_loss: 0.2291 - val_mean_squared_error: 0.2291\n",
            "Epoch 36/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3233 - mean_squared_error: 0.3233 - val_loss: 0.2075 - val_mean_squared_error: 0.2075\n",
            "Epoch 37/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3343 - mean_squared_error: 0.3343 - val_loss: 0.3257 - val_mean_squared_error: 0.3257\n",
            "Epoch 38/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.2414 - val_mean_squared_error: 0.2414\n",
            "Epoch 39/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3203 - mean_squared_error: 0.3203 - val_loss: 0.2400 - val_mean_squared_error: 0.2400\n",
            "Epoch 40/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3232 - mean_squared_error: 0.3232 - val_loss: 0.2854 - val_mean_squared_error: 0.2854\n",
            "Epoch 41/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3221 - mean_squared_error: 0.3221 - val_loss: 0.2800 - val_mean_squared_error: 0.2800\n",
            "Epoch 42/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3228 - mean_squared_error: 0.3228 - val_loss: 0.2657 - val_mean_squared_error: 0.2657\n",
            "Epoch 43/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3247 - mean_squared_error: 0.3247 - val_loss: 0.2448 - val_mean_squared_error: 0.2448\n",
            "Epoch 44/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3160 - mean_squared_error: 0.3160 - val_loss: 0.2714 - val_mean_squared_error: 0.2714\n",
            "Epoch 45/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3176 - mean_squared_error: 0.3176 - val_loss: 0.4900 - val_mean_squared_error: 0.4900\n",
            "Epoch 46/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3268 - mean_squared_error: 0.3268 - val_loss: 0.2591 - val_mean_squared_error: 0.2591\n",
            "Epoch 47/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.3061 - val_mean_squared_error: 0.3061\n",
            "Epoch 48/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3207 - mean_squared_error: 0.3207 - val_loss: 0.3396 - val_mean_squared_error: 0.3396\n",
            "Epoch 49/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3159 - mean_squared_error: 0.3159 - val_loss: 0.3193 - val_mean_squared_error: 0.3193\n",
            "Epoch 50/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3191 - mean_squared_error: 0.3191 - val_loss: 0.2672 - val_mean_squared_error: 0.2672\n",
            "Epoch 51/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3227 - mean_squared_error: 0.3227 - val_loss: 0.2739 - val_mean_squared_error: 0.2739\n",
            "Epoch 52/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3169 - mean_squared_error: 0.3169 - val_loss: 0.3335 - val_mean_squared_error: 0.3335\n",
            "Epoch 53/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3239 - mean_squared_error: 0.3239 - val_loss: 0.3605 - val_mean_squared_error: 0.3605\n",
            "Epoch 54/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3213 - mean_squared_error: 0.3213 - val_loss: 0.2560 - val_mean_squared_error: 0.2560\n",
            "Epoch 55/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3168 - mean_squared_error: 0.3168 - val_loss: 0.2417 - val_mean_squared_error: 0.2417\n",
            "Epoch 56/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3168 - mean_squared_error: 0.3168 - val_loss: 0.2481 - val_mean_squared_error: 0.2481\n",
            "Epoch 57/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3197 - mean_squared_error: 0.3197 - val_loss: 0.3305 - val_mean_squared_error: 0.3305\n",
            "Epoch 58/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3176 - mean_squared_error: 0.3176 - val_loss: 0.2352 - val_mean_squared_error: 0.2352\n",
            "Epoch 59/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3214 - mean_squared_error: 0.3214 - val_loss: 0.2466 - val_mean_squared_error: 0.2466\n",
            "Epoch 60/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3166 - mean_squared_error: 0.3166 - val_loss: 0.2963 - val_mean_squared_error: 0.2963\n",
            "Epoch 61/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3197 - mean_squared_error: 0.3197 - val_loss: 0.2400 - val_mean_squared_error: 0.2400\n",
            "Epoch 62/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3246 - mean_squared_error: 0.3246 - val_loss: 0.4692 - val_mean_squared_error: 0.4692\n",
            "Epoch 63/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3259 - mean_squared_error: 0.3259 - val_loss: 0.2584 - val_mean_squared_error: 0.2584\n",
            "Epoch 64/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3173 - mean_squared_error: 0.3173 - val_loss: 0.2486 - val_mean_squared_error: 0.2486\n",
            "Epoch 65/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3140 - mean_squared_error: 0.3140 - val_loss: 0.2866 - val_mean_squared_error: 0.2866\n",
            "Epoch 66/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3154 - mean_squared_error: 0.3154 - val_loss: 0.3802 - val_mean_squared_error: 0.3802\n",
            "Epoch 67/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3134 - mean_squared_error: 0.3134 - val_loss: 0.3185 - val_mean_squared_error: 0.3185\n",
            "Epoch 68/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3172 - mean_squared_error: 0.3172 - val_loss: 0.2699 - val_mean_squared_error: 0.2699\n",
            "Epoch 69/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3133 - mean_squared_error: 0.3133 - val_loss: 0.2777 - val_mean_squared_error: 0.2777\n",
            "Epoch 70/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3213 - mean_squared_error: 0.3213 - val_loss: 0.2955 - val_mean_squared_error: 0.2955\n",
            "Epoch 71/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3179 - mean_squared_error: 0.3179 - val_loss: 0.2378 - val_mean_squared_error: 0.2378\n",
            "Epoch 72/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3191 - mean_squared_error: 0.3191 - val_loss: 0.2460 - val_mean_squared_error: 0.2460\n",
            "Epoch 73/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3163 - mean_squared_error: 0.3163 - val_loss: 0.2974 - val_mean_squared_error: 0.2974\n",
            "Epoch 74/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3169 - mean_squared_error: 0.3169 - val_loss: 0.2101 - val_mean_squared_error: 0.2101\n",
            "Epoch 75/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3222 - mean_squared_error: 0.3222 - val_loss: 0.2538 - val_mean_squared_error: 0.2538\n",
            "Epoch 76/101\n",
            "109/109 [==============================] - 2s 23ms/step - loss: 0.3100 - mean_squared_error: 0.3100 - val_loss: 0.2713 - val_mean_squared_error: 0.2713\n",
            "Epoch 77/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3141 - mean_squared_error: 0.3141 - val_loss: 0.2597 - val_mean_squared_error: 0.2597\n",
            "Epoch 78/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3276 - mean_squared_error: 0.3276 - val_loss: 0.1989 - val_mean_squared_error: 0.1989\n",
            "Epoch 79/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3157 - mean_squared_error: 0.3157 - val_loss: 0.2147 - val_mean_squared_error: 0.2147\n",
            "Epoch 80/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3136 - mean_squared_error: 0.3136 - val_loss: 0.2752 - val_mean_squared_error: 0.2752\n",
            "Epoch 81/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3184 - mean_squared_error: 0.3184 - val_loss: 0.3714 - val_mean_squared_error: 0.3714\n",
            "Epoch 82/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3152 - mean_squared_error: 0.3152 - val_loss: 0.2351 - val_mean_squared_error: 0.2351\n",
            "Epoch 83/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3145 - mean_squared_error: 0.3145 - val_loss: 0.2405 - val_mean_squared_error: 0.2405\n",
            "Epoch 84/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3166 - mean_squared_error: 0.3166 - val_loss: 0.2323 - val_mean_squared_error: 0.2323\n",
            "Epoch 85/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3161 - mean_squared_error: 0.3161 - val_loss: 0.2728 - val_mean_squared_error: 0.2728\n",
            "Epoch 86/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3133 - mean_squared_error: 0.3133 - val_loss: 0.3040 - val_mean_squared_error: 0.3040\n",
            "Epoch 87/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3112 - mean_squared_error: 0.3112 - val_loss: 0.2640 - val_mean_squared_error: 0.2640\n",
            "Epoch 88/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3197 - mean_squared_error: 0.3197 - val_loss: 0.2689 - val_mean_squared_error: 0.2689\n",
            "Epoch 89/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3139 - mean_squared_error: 0.3139 - val_loss: 0.2196 - val_mean_squared_error: 0.2196\n",
            "Epoch 90/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3231 - mean_squared_error: 0.3231 - val_loss: 0.2306 - val_mean_squared_error: 0.2306\n",
            "Epoch 91/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3230 - mean_squared_error: 0.3230 - val_loss: 0.2074 - val_mean_squared_error: 0.2074\n",
            "Epoch 92/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3191 - mean_squared_error: 0.3191 - val_loss: 0.2328 - val_mean_squared_error: 0.2328\n",
            "Epoch 93/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3188 - mean_squared_error: 0.3188 - val_loss: 0.2761 - val_mean_squared_error: 0.2761\n",
            "Epoch 94/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3116 - mean_squared_error: 0.3116 - val_loss: 0.2472 - val_mean_squared_error: 0.2472\n",
            "Epoch 95/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3110 - mean_squared_error: 0.3110 - val_loss: 0.2185 - val_mean_squared_error: 0.2185\n",
            "Epoch 96/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3163 - mean_squared_error: 0.3163 - val_loss: 0.2184 - val_mean_squared_error: 0.2184\n",
            "Epoch 97/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3112 - mean_squared_error: 0.3112 - val_loss: 0.2273 - val_mean_squared_error: 0.2273\n",
            "Epoch 98/101\n",
            "109/109 [==============================] - 2s 21ms/step - loss: 0.3169 - mean_squared_error: 0.3169 - val_loss: 0.3122 - val_mean_squared_error: 0.3122\n",
            "Epoch 99/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3123 - mean_squared_error: 0.3123 - val_loss: 0.2239 - val_mean_squared_error: 0.2239\n",
            "Epoch 100/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3174 - mean_squared_error: 0.3174 - val_loss: 0.2367 - val_mean_squared_error: 0.2367\n",
            "Epoch 101/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3130 - mean_squared_error: 0.3130 - val_loss: 0.2674 - val_mean_squared_error: 0.2674\n",
            "37/37 [==============================] - 1s 5ms/step\n",
            "Results for location_1 - Split 2\n",
            "RMSE: 0.5174\n",
            "MSE: 0.2677\n",
            "MAE: 0.3587\n",
            "Bias: -0.1287\n",
            "\n",
            "[5.09 4.56 4.4  ... 5.02 4.38 4.31]\n",
            "[4.76 3.69 3.65 ... 4.96 5.06 4.68]\n",
            "length of X_test = 1158\n",
            "length of X_train = 3477\n",
            "length of Y_test = 1158\n",
            "length of Y_train = 3477\n",
            "sheet name location_1 : num_split 2 :  X_train [[[3.93e+00 9.00e-02 1.00e+00]]\n",
            "\n",
            " [[5.18e+00 8.00e-02 2.00e+00]]\n",
            "\n",
            " [[5.21e+00 1.00e-01 3.00e+00]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[4.08e+00 1.60e-01 3.63e+02]]\n",
            "\n",
            " [[4.48e+00 1.30e-01 3.64e+02]]\n",
            "\n",
            " [[4.20e+00 1.50e-01 3.65e+02]]]\n",
            "sheet name location_1 : num_split 2 :  X_test [[[5.09e+00 2.50e-01 1.98e+02]]\n",
            "\n",
            " [[4.56e+00 3.00e-01 1.99e+02]]\n",
            "\n",
            " [[4.40e+00 3.60e-01 2.00e+02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[5.02e+00 2.10e-01 2.97e+02]]\n",
            "\n",
            " [[4.38e+00 5.70e-01 2.98e+02]]\n",
            "\n",
            " [[4.31e+00 3.20e-01 2.99e+02]]]\n",
            "Reloading Tuner from RandomSearch\\location_1\\split_2\\BTP\\tuner0.json\n",
            "{'space': [{'class_name': 'Int', 'config': {'name': 'first_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 64, 'max_value': 256, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'second_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'third_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 8, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'dense_layer_units', 'default': None, 'conditions': [], 'min_value': 8, 'max_value': 64, 'step': 8, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.001, 'conditions': [], 'values': [0.001, 0.0001, 1e-05], 'ordered': True}}], 'values': {'first_hidden_layer_units': 192, 'second_hidden_layer_units': 112, 'third_hidden_layer_units': 40, 'dense_layer_units': 64, 'learning_rate': 0.0001}}\n",
            "Epoch 1/101\n",
            "109/109 [==============================] - 8s 26ms/step - loss: 13.6637 - mean_squared_error: 13.6637 - val_loss: 5.3334 - val_mean_squared_error: 5.3334\n",
            "Epoch 2/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 2.5251 - mean_squared_error: 2.5251 - val_loss: 1.1258 - val_mean_squared_error: 1.1258\n",
            "Epoch 3/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 1.1347 - mean_squared_error: 1.1347 - val_loss: 0.8130 - val_mean_squared_error: 0.8130\n",
            "Epoch 4/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.8259 - mean_squared_error: 0.8259 - val_loss: 0.6658 - val_mean_squared_error: 0.6658\n",
            "Epoch 5/101\n",
            "109/109 [==============================] - 2s 21ms/step - loss: 0.6171 - mean_squared_error: 0.6171 - val_loss: 0.5190 - val_mean_squared_error: 0.5190\n",
            "Epoch 6/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.4880 - mean_squared_error: 0.4880 - val_loss: 0.4483 - val_mean_squared_error: 0.4483\n",
            "Epoch 7/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.4266 - mean_squared_error: 0.4266 - val_loss: 0.4139 - val_mean_squared_error: 0.4139\n",
            "Epoch 8/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.4038 - mean_squared_error: 0.4038 - val_loss: 0.2871 - val_mean_squared_error: 0.2871\n",
            "Epoch 9/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3816 - mean_squared_error: 0.3816 - val_loss: 0.3251 - val_mean_squared_error: 0.3251\n",
            "Epoch 10/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3841 - mean_squared_error: 0.3841 - val_loss: 0.6824 - val_mean_squared_error: 0.6824\n",
            "Epoch 11/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3919 - mean_squared_error: 0.3919 - val_loss: 0.3452 - val_mean_squared_error: 0.3452\n",
            "Epoch 12/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3753 - mean_squared_error: 0.3753 - val_loss: 0.4325 - val_mean_squared_error: 0.4325\n",
            "Epoch 13/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3719 - mean_squared_error: 0.3719 - val_loss: 0.4327 - val_mean_squared_error: 0.4327\n",
            "Epoch 14/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3674 - mean_squared_error: 0.3674 - val_loss: 0.2842 - val_mean_squared_error: 0.2842\n",
            "Epoch 15/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3600 - mean_squared_error: 0.3600 - val_loss: 0.3329 - val_mean_squared_error: 0.3329\n",
            "Epoch 16/101\n",
            "109/109 [==============================] - 2s 22ms/step - loss: 0.3635 - mean_squared_error: 0.3635 - val_loss: 0.2469 - val_mean_squared_error: 0.2469\n",
            "Epoch 17/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3593 - mean_squared_error: 0.3593 - val_loss: 0.3535 - val_mean_squared_error: 0.3535\n",
            "Epoch 18/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3616 - mean_squared_error: 0.3616 - val_loss: 0.3817 - val_mean_squared_error: 0.3817\n",
            "Epoch 19/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3690 - mean_squared_error: 0.3690 - val_loss: 0.2578 - val_mean_squared_error: 0.2578\n",
            "Epoch 20/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3596 - mean_squared_error: 0.3596 - val_loss: 0.2589 - val_mean_squared_error: 0.2589\n",
            "Epoch 21/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3707 - mean_squared_error: 0.3707 - val_loss: 0.2705 - val_mean_squared_error: 0.2705\n",
            "Epoch 22/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3627 - mean_squared_error: 0.3627 - val_loss: 0.3623 - val_mean_squared_error: 0.3623\n",
            "Epoch 23/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3509 - mean_squared_error: 0.3509 - val_loss: 0.3162 - val_mean_squared_error: 0.3162\n",
            "Epoch 24/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3524 - mean_squared_error: 0.3524 - val_loss: 0.3106 - val_mean_squared_error: 0.3106\n",
            "Epoch 25/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3482 - mean_squared_error: 0.3482 - val_loss: 0.2138 - val_mean_squared_error: 0.2138\n",
            "Epoch 26/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3680 - mean_squared_error: 0.3680 - val_loss: 0.2952 - val_mean_squared_error: 0.2952\n",
            "Epoch 27/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3522 - mean_squared_error: 0.3522 - val_loss: 0.2578 - val_mean_squared_error: 0.2578\n",
            "Epoch 28/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3544 - mean_squared_error: 0.3544 - val_loss: 0.2377 - val_mean_squared_error: 0.2377\n",
            "Epoch 29/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3432 - mean_squared_error: 0.3432 - val_loss: 0.2850 - val_mean_squared_error: 0.2850\n",
            "Epoch 30/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3438 - mean_squared_error: 0.3438 - val_loss: 0.3911 - val_mean_squared_error: 0.3911\n",
            "Epoch 31/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3427 - mean_squared_error: 0.3427 - val_loss: 0.2889 - val_mean_squared_error: 0.2889\n",
            "Epoch 32/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3476 - mean_squared_error: 0.3476 - val_loss: 0.2651 - val_mean_squared_error: 0.2651\n",
            "Epoch 33/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3438 - mean_squared_error: 0.3438 - val_loss: 0.2876 - val_mean_squared_error: 0.2876\n",
            "Epoch 34/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3449 - mean_squared_error: 0.3449 - val_loss: 0.2543 - val_mean_squared_error: 0.2543\n",
            "Epoch 35/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3466 - mean_squared_error: 0.3466 - val_loss: 0.3008 - val_mean_squared_error: 0.3008\n",
            "Epoch 36/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3411 - mean_squared_error: 0.3411 - val_loss: 0.3185 - val_mean_squared_error: 0.3185\n",
            "Epoch 37/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3394 - mean_squared_error: 0.3394 - val_loss: 0.2767 - val_mean_squared_error: 0.2767\n",
            "Epoch 38/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3435 - mean_squared_error: 0.3435 - val_loss: 0.2497 - val_mean_squared_error: 0.2497\n",
            "Epoch 39/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3566 - mean_squared_error: 0.3566 - val_loss: 0.2515 - val_mean_squared_error: 0.2515\n",
            "Epoch 40/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3362 - mean_squared_error: 0.3362 - val_loss: 0.2740 - val_mean_squared_error: 0.2740\n",
            "Epoch 41/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3462 - mean_squared_error: 0.3462 - val_loss: 0.2287 - val_mean_squared_error: 0.2287\n",
            "Epoch 42/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3410 - mean_squared_error: 0.3410 - val_loss: 0.3056 - val_mean_squared_error: 0.3056\n",
            "Epoch 43/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3379 - mean_squared_error: 0.3379 - val_loss: 0.2448 - val_mean_squared_error: 0.2448\n",
            "Epoch 44/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3425 - mean_squared_error: 0.3425 - val_loss: 0.3354 - val_mean_squared_error: 0.3354\n",
            "Epoch 45/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3393 - mean_squared_error: 0.3393 - val_loss: 0.2608 - val_mean_squared_error: 0.2608\n",
            "Epoch 46/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3411 - mean_squared_error: 0.3411 - val_loss: 0.2599 - val_mean_squared_error: 0.2599\n",
            "Epoch 47/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3603 - mean_squared_error: 0.3603 - val_loss: 0.3424 - val_mean_squared_error: 0.3424\n",
            "Epoch 48/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3479 - mean_squared_error: 0.3479 - val_loss: 0.2958 - val_mean_squared_error: 0.2958\n",
            "Epoch 49/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3371 - mean_squared_error: 0.3371 - val_loss: 0.2414 - val_mean_squared_error: 0.2414\n",
            "Epoch 50/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3474 - mean_squared_error: 0.3474 - val_loss: 0.2798 - val_mean_squared_error: 0.2798\n",
            "Epoch 51/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3365 - mean_squared_error: 0.3365 - val_loss: 0.4275 - val_mean_squared_error: 0.4275\n",
            "Epoch 52/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3314 - mean_squared_error: 0.3314 - val_loss: 0.3137 - val_mean_squared_error: 0.3137\n",
            "Epoch 53/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3489 - mean_squared_error: 0.3489 - val_loss: 0.3494 - val_mean_squared_error: 0.3494\n",
            "Epoch 54/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.3363 - val_mean_squared_error: 0.3363\n",
            "Epoch 55/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3370 - mean_squared_error: 0.3370 - val_loss: 0.2762 - val_mean_squared_error: 0.2762\n",
            "Epoch 56/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3275 - mean_squared_error: 0.3275 - val_loss: 0.2347 - val_mean_squared_error: 0.2347\n",
            "Epoch 57/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3390 - mean_squared_error: 0.3390 - val_loss: 0.3078 - val_mean_squared_error: 0.3078\n",
            "Epoch 58/101\n",
            "109/109 [==============================] - 2s 23ms/step - loss: 0.3333 - mean_squared_error: 0.3333 - val_loss: 0.2743 - val_mean_squared_error: 0.2743\n",
            "Epoch 59/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3307 - mean_squared_error: 0.3307 - val_loss: 0.4442 - val_mean_squared_error: 0.4442\n",
            "Epoch 60/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3382 - mean_squared_error: 0.3382 - val_loss: 0.3026 - val_mean_squared_error: 0.3026\n",
            "Epoch 61/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3371 - mean_squared_error: 0.3371 - val_loss: 0.4692 - val_mean_squared_error: 0.4692\n",
            "Epoch 62/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3330 - mean_squared_error: 0.3330 - val_loss: 0.2677 - val_mean_squared_error: 0.2677\n",
            "Epoch 63/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3278 - mean_squared_error: 0.3278 - val_loss: 0.3121 - val_mean_squared_error: 0.3121\n",
            "Epoch 64/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3291 - mean_squared_error: 0.3291 - val_loss: 0.2775 - val_mean_squared_error: 0.2775\n",
            "Epoch 65/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.2793 - val_mean_squared_error: 0.2793\n",
            "Epoch 66/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3233 - mean_squared_error: 0.3233 - val_loss: 0.3001 - val_mean_squared_error: 0.3001\n",
            "Epoch 67/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3300 - mean_squared_error: 0.3300 - val_loss: 0.3335 - val_mean_squared_error: 0.3335\n",
            "Epoch 68/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3336 - mean_squared_error: 0.3336 - val_loss: 0.2606 - val_mean_squared_error: 0.2606\n",
            "Epoch 69/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3314 - mean_squared_error: 0.3314 - val_loss: 0.2892 - val_mean_squared_error: 0.2892\n",
            "Epoch 70/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3355 - mean_squared_error: 0.3355 - val_loss: 0.3456 - val_mean_squared_error: 0.3456\n",
            "Epoch 71/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3337 - mean_squared_error: 0.3337 - val_loss: 0.3414 - val_mean_squared_error: 0.3414\n",
            "Epoch 72/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3306 - mean_squared_error: 0.3306 - val_loss: 0.2732 - val_mean_squared_error: 0.2732\n",
            "Epoch 73/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3298 - mean_squared_error: 0.3298 - val_loss: 0.2985 - val_mean_squared_error: 0.2985\n",
            "Epoch 74/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3245 - mean_squared_error: 0.3245 - val_loss: 0.2453 - val_mean_squared_error: 0.2453\n",
            "Epoch 75/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3245 - mean_squared_error: 0.3245 - val_loss: 0.2805 - val_mean_squared_error: 0.2805\n",
            "Epoch 76/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3256 - mean_squared_error: 0.3256 - val_loss: 0.2795 - val_mean_squared_error: 0.2795\n",
            "Epoch 77/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3297 - mean_squared_error: 0.3297 - val_loss: 0.2497 - val_mean_squared_error: 0.2497\n",
            "Epoch 78/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3295 - mean_squared_error: 0.3295 - val_loss: 0.2410 - val_mean_squared_error: 0.2410\n",
            "Epoch 79/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3387 - mean_squared_error: 0.3387 - val_loss: 0.2576 - val_mean_squared_error: 0.2576\n",
            "Epoch 80/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3275 - mean_squared_error: 0.3275 - val_loss: 0.2523 - val_mean_squared_error: 0.2523\n",
            "Epoch 81/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3239 - mean_squared_error: 0.3239 - val_loss: 0.2242 - val_mean_squared_error: 0.2242\n",
            "Epoch 82/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3245 - mean_squared_error: 0.3245 - val_loss: 0.3018 - val_mean_squared_error: 0.3018\n",
            "Epoch 83/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3254 - mean_squared_error: 0.3254 - val_loss: 0.3304 - val_mean_squared_error: 0.3304\n",
            "Epoch 84/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3283 - mean_squared_error: 0.3283 - val_loss: 0.3183 - val_mean_squared_error: 0.3183\n",
            "Epoch 85/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3233 - mean_squared_error: 0.3233 - val_loss: 0.2833 - val_mean_squared_error: 0.2833\n",
            "Epoch 86/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3274 - mean_squared_error: 0.3274 - val_loss: 0.3693 - val_mean_squared_error: 0.3693\n",
            "Epoch 87/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3242 - mean_squared_error: 0.3242 - val_loss: 0.2534 - val_mean_squared_error: 0.2534\n",
            "Epoch 88/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3295 - mean_squared_error: 0.3295 - val_loss: 0.2445 - val_mean_squared_error: 0.2445\n",
            "Epoch 89/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3306 - mean_squared_error: 0.3306 - val_loss: 0.2962 - val_mean_squared_error: 0.2962\n",
            "Epoch 90/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3201 - mean_squared_error: 0.3201 - val_loss: 0.2156 - val_mean_squared_error: 0.2156\n",
            "Epoch 91/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3318 - mean_squared_error: 0.3318 - val_loss: 0.2305 - val_mean_squared_error: 0.2305\n",
            "Epoch 92/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3249 - mean_squared_error: 0.3249 - val_loss: 0.3233 - val_mean_squared_error: 0.3233\n",
            "Epoch 93/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3326 - mean_squared_error: 0.3326 - val_loss: 0.3077 - val_mean_squared_error: 0.3077\n",
            "Epoch 94/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3253 - mean_squared_error: 0.3253 - val_loss: 0.2381 - val_mean_squared_error: 0.2381\n",
            "Epoch 95/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3247 - mean_squared_error: 0.3247 - val_loss: 0.3093 - val_mean_squared_error: 0.3093\n",
            "Epoch 96/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3214 - mean_squared_error: 0.3214 - val_loss: 0.2861 - val_mean_squared_error: 0.2861\n",
            "Epoch 97/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.3621 - val_mean_squared_error: 0.3621\n",
            "Epoch 98/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3242 - mean_squared_error: 0.3242 - val_loss: 0.2327 - val_mean_squared_error: 0.2327\n",
            "Epoch 99/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3197 - mean_squared_error: 0.3197 - val_loss: 0.2261 - val_mean_squared_error: 0.2261\n",
            "Epoch 100/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.3240 - mean_squared_error: 0.3240 - val_loss: 0.2683 - val_mean_squared_error: 0.2683\n",
            "Epoch 101/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.3258 - mean_squared_error: 0.3258 - val_loss: 0.2023 - val_mean_squared_error: 0.2023\n",
            "37/37 [==============================] - 1s 5ms/step\n",
            "Results for location_1 - Split 3\n",
            "RMSE: 0.5242\n",
            "MSE: 0.2748\n",
            "MAE: 0.3822\n",
            "Bias: -0.1269\n",
            "\n",
            "[3.93 3.73 4.93 ... 3.71 4.07 4.73]\n",
            "[4.27 4.02 4.69 ... 3.77 3.87 4.49]\n",
            "length of X_test = 1158\n",
            "length of X_train = 3477\n",
            "length of Y_test = 1158\n",
            "length of Y_train = 3477\n",
            "sheet name location_1 : num_split 3 :  X_train [[[3.93e+00 9.00e-02 1.00e+00]]\n",
            "\n",
            " [[5.18e+00 8.00e-02 2.00e+00]]\n",
            "\n",
            " [[5.21e+00 1.00e-01 3.00e+00]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[4.08e+00 1.60e-01 3.63e+02]]\n",
            "\n",
            " [[4.48e+00 1.30e-01 3.64e+02]]\n",
            "\n",
            " [[4.20e+00 1.50e-01 3.65e+02]]]\n",
            "sheet name location_1 : num_split 3 :  X_test [[[3.93e+00 3.20e-01 3.00e+02]]\n",
            "\n",
            " [[3.73e+00 3.00e-01 3.01e+02]]\n",
            "\n",
            " [[4.93e+00 1.90e-01 3.02e+02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[3.71e+00 2.30e-01 3.60e+02]]\n",
            "\n",
            " [[4.07e+00 1.70e-01 3.61e+02]]\n",
            "\n",
            " [[4.73e+00 2.20e-01 3.62e+02]]]\n",
            "Reloading Tuner from RandomSearch\\location_1\\split_3\\BTP\\tuner0.json\n",
            "{'space': [{'class_name': 'Int', 'config': {'name': 'first_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 64, 'max_value': 256, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'second_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'third_hidden_layer_units', 'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 8, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'dense_layer_units', 'default': None, 'conditions': [], 'min_value': 8, 'max_value': 64, 'step': 8, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.001, 'conditions': [], 'values': [0.001, 0.0001, 1e-05], 'ordered': True}}], 'values': {'first_hidden_layer_units': 160, 'second_hidden_layer_units': 80, 'third_hidden_layer_units': 32, 'dense_layer_units': 48, 'learning_rate': 0.0001}}\n",
            "Epoch 1/101\n",
            "109/109 [==============================] - 8s 24ms/step - loss: 16.5733 - mean_squared_error: 16.5733 - val_loss: 8.5913 - val_mean_squared_error: 8.5913\n",
            "Epoch 2/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 3.7123 - mean_squared_error: 3.7123 - val_loss: 1.8270 - val_mean_squared_error: 1.8270\n",
            "Epoch 3/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 1.2841 - mean_squared_error: 1.2841 - val_loss: 1.0220 - val_mean_squared_error: 1.0220\n",
            "Epoch 4/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.8623 - mean_squared_error: 0.8623 - val_loss: 0.7007 - val_mean_squared_error: 0.7007\n",
            "Epoch 5/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.6468 - mean_squared_error: 0.6468 - val_loss: 0.5619 - val_mean_squared_error: 0.5619\n",
            "Epoch 6/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.4941 - mean_squared_error: 0.4941 - val_loss: 0.4783 - val_mean_squared_error: 0.4783\n",
            "Epoch 7/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.4164 - mean_squared_error: 0.4164 - val_loss: 0.3169 - val_mean_squared_error: 0.3169\n",
            "Epoch 8/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3666 - mean_squared_error: 0.3666 - val_loss: 0.3344 - val_mean_squared_error: 0.3344\n",
            "Epoch 9/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3545 - mean_squared_error: 0.3545 - val_loss: 0.2663 - val_mean_squared_error: 0.2663\n",
            "Epoch 10/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3397 - mean_squared_error: 0.3397 - val_loss: 0.2990 - val_mean_squared_error: 0.2990\n",
            "Epoch 11/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3258 - mean_squared_error: 0.3258 - val_loss: 0.3347 - val_mean_squared_error: 0.3347\n",
            "Epoch 12/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3122 - mean_squared_error: 0.3122 - val_loss: 0.2468 - val_mean_squared_error: 0.2468\n",
            "Epoch 13/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3165 - mean_squared_error: 0.3165 - val_loss: 0.2431 - val_mean_squared_error: 0.2431\n",
            "Epoch 14/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3116 - mean_squared_error: 0.3116 - val_loss: 0.2299 - val_mean_squared_error: 0.2299\n",
            "Epoch 15/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.2264 - val_mean_squared_error: 0.2264\n",
            "Epoch 16/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3046 - mean_squared_error: 0.3046 - val_loss: 0.2565 - val_mean_squared_error: 0.2565\n",
            "Epoch 17/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3008 - mean_squared_error: 0.3008 - val_loss: 0.3413 - val_mean_squared_error: 0.3413\n",
            "Epoch 18/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3046 - mean_squared_error: 0.3046 - val_loss: 0.3594 - val_mean_squared_error: 0.3594\n",
            "Epoch 19/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3109 - mean_squared_error: 0.3109 - val_loss: 0.2677 - val_mean_squared_error: 0.2677\n",
            "Epoch 20/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3008 - mean_squared_error: 0.3008 - val_loss: 0.3709 - val_mean_squared_error: 0.3709\n",
            "Epoch 21/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2968 - mean_squared_error: 0.2968 - val_loss: 0.2491 - val_mean_squared_error: 0.2491\n",
            "Epoch 22/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2960 - mean_squared_error: 0.2960 - val_loss: 0.2338 - val_mean_squared_error: 0.2338\n",
            "Epoch 23/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3110 - mean_squared_error: 0.3110 - val_loss: 0.4029 - val_mean_squared_error: 0.4029\n",
            "Epoch 24/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3091 - mean_squared_error: 0.3091 - val_loss: 0.2387 - val_mean_squared_error: 0.2387\n",
            "Epoch 25/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3005 - mean_squared_error: 0.3005 - val_loss: 0.2417 - val_mean_squared_error: 0.2417\n",
            "Epoch 26/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3015 - mean_squared_error: 0.3015 - val_loss: 0.3121 - val_mean_squared_error: 0.3121\n",
            "Epoch 27/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2985 - mean_squared_error: 0.2985 - val_loss: 0.2458 - val_mean_squared_error: 0.2458\n",
            "Epoch 28/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2943 - mean_squared_error: 0.2943 - val_loss: 0.2911 - val_mean_squared_error: 0.2911\n",
            "Epoch 29/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2949 - mean_squared_error: 0.2949 - val_loss: 0.2686 - val_mean_squared_error: 0.2686\n",
            "Epoch 30/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2953 - mean_squared_error: 0.2953 - val_loss: 0.2764 - val_mean_squared_error: 0.2764\n",
            "Epoch 31/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2926 - mean_squared_error: 0.2926 - val_loss: 0.2639 - val_mean_squared_error: 0.2639\n",
            "Epoch 32/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2910 - mean_squared_error: 0.2910 - val_loss: 0.2619 - val_mean_squared_error: 0.2619\n",
            "Epoch 33/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2940 - mean_squared_error: 0.2940 - val_loss: 0.2789 - val_mean_squared_error: 0.2789\n",
            "Epoch 34/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2968 - mean_squared_error: 0.2968 - val_loss: 0.2752 - val_mean_squared_error: 0.2752\n",
            "Epoch 35/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2939 - mean_squared_error: 0.2939 - val_loss: 0.3410 - val_mean_squared_error: 0.3410\n",
            "Epoch 36/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2901 - mean_squared_error: 0.2901 - val_loss: 0.3048 - val_mean_squared_error: 0.3048\n",
            "Epoch 37/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2909 - mean_squared_error: 0.2909 - val_loss: 0.2769 - val_mean_squared_error: 0.2769\n",
            "Epoch 38/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2959 - mean_squared_error: 0.2959 - val_loss: 0.2714 - val_mean_squared_error: 0.2714\n",
            "Epoch 39/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2919 - mean_squared_error: 0.2919 - val_loss: 0.3634 - val_mean_squared_error: 0.3634\n",
            "Epoch 40/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2917 - mean_squared_error: 0.2917 - val_loss: 0.2821 - val_mean_squared_error: 0.2821\n",
            "Epoch 41/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2913 - mean_squared_error: 0.2913 - val_loss: 0.2599 - val_mean_squared_error: 0.2599\n",
            "Epoch 42/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.3018 - mean_squared_error: 0.3018 - val_loss: 0.2410 - val_mean_squared_error: 0.2410\n",
            "Epoch 43/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2931 - mean_squared_error: 0.2931 - val_loss: 0.3885 - val_mean_squared_error: 0.3885\n",
            "Epoch 44/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2852 - mean_squared_error: 0.2852 - val_loss: 0.2449 - val_mean_squared_error: 0.2449\n",
            "Epoch 45/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.2879 - mean_squared_error: 0.2879 - val_loss: 0.2318 - val_mean_squared_error: 0.2318\n",
            "Epoch 46/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2953 - mean_squared_error: 0.2953 - val_loss: 0.3293 - val_mean_squared_error: 0.3293\n",
            "Epoch 47/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2892 - mean_squared_error: 0.2892 - val_loss: 0.2996 - val_mean_squared_error: 0.2996\n",
            "Epoch 48/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2900 - mean_squared_error: 0.2900 - val_loss: 0.2546 - val_mean_squared_error: 0.2546\n",
            "Epoch 49/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2926 - mean_squared_error: 0.2926 - val_loss: 0.3221 - val_mean_squared_error: 0.3221\n",
            "Epoch 50/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2901 - mean_squared_error: 0.2901 - val_loss: 0.2861 - val_mean_squared_error: 0.2861\n",
            "Epoch 51/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2923 - mean_squared_error: 0.2923 - val_loss: 0.3401 - val_mean_squared_error: 0.3401\n",
            "Epoch 52/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.3025 - mean_squared_error: 0.3025 - val_loss: 0.2985 - val_mean_squared_error: 0.2985\n",
            "Epoch 53/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2929 - mean_squared_error: 0.2929 - val_loss: 0.2334 - val_mean_squared_error: 0.2334\n",
            "Epoch 54/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2903 - mean_squared_error: 0.2903 - val_loss: 0.2777 - val_mean_squared_error: 0.2777\n",
            "Epoch 55/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2871 - mean_squared_error: 0.2871 - val_loss: 0.2451 - val_mean_squared_error: 0.2451\n",
            "Epoch 56/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2844 - mean_squared_error: 0.2844 - val_loss: 0.3123 - val_mean_squared_error: 0.3123\n",
            "Epoch 57/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2828 - mean_squared_error: 0.2828 - val_loss: 0.2590 - val_mean_squared_error: 0.2590\n",
            "Epoch 58/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2865 - mean_squared_error: 0.2865 - val_loss: 0.2167 - val_mean_squared_error: 0.2167\n",
            "Epoch 59/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2838 - mean_squared_error: 0.2838 - val_loss: 0.3463 - val_mean_squared_error: 0.3463\n",
            "Epoch 60/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2866 - mean_squared_error: 0.2866 - val_loss: 0.2559 - val_mean_squared_error: 0.2559\n",
            "Epoch 61/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2918 - mean_squared_error: 0.2918 - val_loss: 0.2368 - val_mean_squared_error: 0.2368\n",
            "Epoch 62/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2864 - mean_squared_error: 0.2864 - val_loss: 0.2884 - val_mean_squared_error: 0.2884\n",
            "Epoch 63/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2850 - mean_squared_error: 0.2850 - val_loss: 0.2276 - val_mean_squared_error: 0.2276\n",
            "Epoch 64/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2839 - mean_squared_error: 0.2839 - val_loss: 0.2891 - val_mean_squared_error: 0.2891\n",
            "Epoch 65/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2876 - mean_squared_error: 0.2876 - val_loss: 0.2241 - val_mean_squared_error: 0.2241\n",
            "Epoch 66/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2816 - mean_squared_error: 0.2816 - val_loss: 0.2731 - val_mean_squared_error: 0.2731\n",
            "Epoch 67/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2828 - mean_squared_error: 0.2828 - val_loss: 0.2646 - val_mean_squared_error: 0.2646\n",
            "Epoch 68/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2891 - mean_squared_error: 0.2891 - val_loss: 0.2883 - val_mean_squared_error: 0.2883\n",
            "Epoch 69/101\n",
            "109/109 [==============================] - 2s 20ms/step - loss: 0.2812 - mean_squared_error: 0.2812 - val_loss: 0.2693 - val_mean_squared_error: 0.2693\n",
            "Epoch 70/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.2824 - mean_squared_error: 0.2824 - val_loss: 0.3237 - val_mean_squared_error: 0.3237\n",
            "Epoch 71/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.2816 - mean_squared_error: 0.2816 - val_loss: 0.2230 - val_mean_squared_error: 0.2230\n",
            "Epoch 72/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2807 - mean_squared_error: 0.2807 - val_loss: 0.2718 - val_mean_squared_error: 0.2718\n",
            "Epoch 73/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2883 - mean_squared_error: 0.2883 - val_loss: 0.2579 - val_mean_squared_error: 0.2579\n",
            "Epoch 74/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.2839 - mean_squared_error: 0.2839 - val_loss: 0.2955 - val_mean_squared_error: 0.2955\n",
            "Epoch 75/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2893 - mean_squared_error: 0.2893 - val_loss: 0.2632 - val_mean_squared_error: 0.2632\n",
            "Epoch 76/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.2810 - mean_squared_error: 0.2810 - val_loss: 0.3293 - val_mean_squared_error: 0.3293\n",
            "Epoch 77/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2849 - mean_squared_error: 0.2849 - val_loss: 0.3279 - val_mean_squared_error: 0.3279\n",
            "Epoch 78/101\n",
            "109/109 [==============================] - 2s 17ms/step - loss: 0.2848 - mean_squared_error: 0.2848 - val_loss: 0.3005 - val_mean_squared_error: 0.3005\n",
            "Epoch 79/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.2826 - mean_squared_error: 0.2826 - val_loss: 0.3590 - val_mean_squared_error: 0.3590\n",
            "Epoch 80/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2868 - mean_squared_error: 0.2868 - val_loss: 0.2646 - val_mean_squared_error: 0.2646\n",
            "Epoch 81/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2811 - mean_squared_error: 0.2811 - val_loss: 0.3492 - val_mean_squared_error: 0.3492\n",
            "Epoch 82/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2806 - mean_squared_error: 0.2806 - val_loss: 0.2525 - val_mean_squared_error: 0.2525\n",
            "Epoch 83/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2823 - mean_squared_error: 0.2823 - val_loss: 0.3113 - val_mean_squared_error: 0.3113\n",
            "Epoch 84/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2833 - mean_squared_error: 0.2833 - val_loss: 0.3221 - val_mean_squared_error: 0.3221\n",
            "Epoch 85/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2821 - mean_squared_error: 0.2821 - val_loss: 0.2718 - val_mean_squared_error: 0.2718\n",
            "Epoch 86/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2808 - mean_squared_error: 0.2808 - val_loss: 0.2741 - val_mean_squared_error: 0.2741\n",
            "Epoch 87/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2785 - mean_squared_error: 0.2785 - val_loss: 0.3296 - val_mean_squared_error: 0.3296\n",
            "Epoch 88/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.2804 - mean_squared_error: 0.2804 - val_loss: 0.2861 - val_mean_squared_error: 0.2861\n",
            "Epoch 89/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.2798 - mean_squared_error: 0.2798 - val_loss: 0.2285 - val_mean_squared_error: 0.2285\n",
            "Epoch 90/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2846 - mean_squared_error: 0.2846 - val_loss: 0.3938 - val_mean_squared_error: 0.3938\n",
            "Epoch 91/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2861 - mean_squared_error: 0.2861 - val_loss: 0.3101 - val_mean_squared_error: 0.3101\n",
            "Epoch 92/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2811 - mean_squared_error: 0.2811 - val_loss: 0.2597 - val_mean_squared_error: 0.2597\n",
            "Epoch 93/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2810 - mean_squared_error: 0.2810 - val_loss: 0.4087 - val_mean_squared_error: 0.4087\n",
            "Epoch 94/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.2796 - mean_squared_error: 0.2796 - val_loss: 0.2417 - val_mean_squared_error: 0.2417\n",
            "Epoch 95/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2789 - mean_squared_error: 0.2789 - val_loss: 0.2039 - val_mean_squared_error: 0.2039\n",
            "Epoch 96/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2815 - mean_squared_error: 0.2815 - val_loss: 0.2598 - val_mean_squared_error: 0.2598\n",
            "Epoch 97/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2840 - mean_squared_error: 0.2840 - val_loss: 0.2802 - val_mean_squared_error: 0.2802\n",
            "Epoch 98/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.2797 - mean_squared_error: 0.2797 - val_loss: 0.2082 - val_mean_squared_error: 0.2082\n",
            "Epoch 99/101\n",
            "109/109 [==============================] - 2s 19ms/step - loss: 0.2820 - mean_squared_error: 0.2820 - val_loss: 0.2316 - val_mean_squared_error: 0.2316\n",
            "Epoch 100/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2814 - mean_squared_error: 0.2814 - val_loss: 0.2480 - val_mean_squared_error: 0.2480\n",
            "Epoch 101/101\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.2793 - mean_squared_error: 0.2793 - val_loss: 0.2548 - val_mean_squared_error: 0.2548\n",
            "37/37 [==============================] - 1s 5ms/step\n",
            "Results for location_1 - Split 4\n",
            "RMSE: 0.6787\n",
            "MSE: 0.4606\n",
            "MAE: 0.5955\n",
            "Bias: 0.5416\n",
            "\n",
            "Average Metrics for location_1:\n",
            "Average RMSE: 0.6189\n",
            "Average MSE: 0.3934\n",
            "Average MAE: 0.4746\n",
            "Average Bias: -0.0453\n",
            "\n",
            "Metrics of Raw Data location_1:\n",
            "RMSE: 0.7352\n",
            "MSE: 0.5405\n",
            "MAE: 0.5726\n",
            "Bias: -0.4445\n",
            "\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "[Errno 28] No space left on device",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:261\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m     handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m     lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m )\n\u001b[1;32m--> 261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_header()\n\u001b[1;32m--> 266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_body()\n",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:304\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_chunk(start_i, end_i)\n",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:315\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    314\u001b[0m ix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_index[slicer]\u001b[39m.\u001b[39m_format_native_types(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_number_format)\n\u001b[1;32m--> 315\u001b[0m libwriters\u001b[39m.\u001b[39mwrite_csv_rows(\n\u001b[0;32m    316\u001b[0m     data,\n\u001b[0;32m    317\u001b[0m     ix,\n\u001b[0;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnlevels,\n\u001b[0;32m    319\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcols,\n\u001b[0;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter,\n\u001b[0;32m    321\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\writers.pyx:72\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Hello\\OneDrive\\Desktop\\BTP\\2.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Hello/OneDrive/Desktop/BTP/2.ipynb#W4sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m result_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_directory, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msheet_name\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Hello/OneDrive/Desktop/BTP/2.ipynb#W4sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m result_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(all_results)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Hello/OneDrive/Desktop/BTP/2.ipynb#W4sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m result_df\u001b[39m.\u001b[39mto_csv(result_file, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:133\u001b[0m, in \u001b[0;36mIOHandles.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
            "File \u001b[1;32mc:\\Users\\Hello\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:125\u001b[0m, in \u001b[0;36mIOHandles.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreated_handles\u001b[39m.\u001b[39mremove(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[0;32m    124\u001b[0m \u001b[39mfor\u001b[39;00m handle \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreated_handles:\n\u001b[1;32m--> 125\u001b[0m     handle\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreated_handles \u001b[39m=\u001b[39m []\n\u001b[0;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_wrapped \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "# Initializing a list to store all metrics\n",
        "output_directory = \"C:/Users/Hello/OneDrive/Desktop/BTP\"\n",
        "all_metrics = []\n",
        "for sheet_name in excel_file.sheet_names[:10]:\n",
        "    df = excel_file.parse(sheet_name)\n",
        "\n",
        "    meanmodeldata_column = [col for col in df.columns if re.match(r'meanmodeldata_\\d+\\.\\d+_\\d+\\.\\d+', col)]\n",
        "    observeddata_column = [col for col in df.columns if re.match(r'observeddata_\\d+\\.\\d+_\\d+\\.\\d+', col)]\n",
        "\n",
        "    if meanmodeldata_column and observeddata_column:\n",
        "        meanmodeldata_column = meanmodeldata_column[0]  \n",
        "        observeddata_column = observeddata_column[0]  \n",
        "    else:\n",
        "        print(f\"Sheet '{sheet_name}' does not contain the expected columns with the pattern.\")\n",
        "        continue\n",
        "\n",
        "    meanmodeldata = df[meanmodeldata_column].values\n",
        "    observeddata = df[observeddata_column].values\n",
        "    \n",
        "    idates = df['idates'].values\n",
        "    imonths = df['imonths'].values\n",
        "    iyears = df['iyears'].values\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['idates', 'imonths', 'iyears']].astype(str).agg('/'.join, axis=1), format='%d/%m/%Y')\n",
        "    df.drop(columns=['idates', 'imonths', 'iyears'], inplace=True)\n",
        "    Date = df['Date'].values\n",
        "\n",
        "    df['julean_day'] = pd.to_datetime(df['Date']).dt.dayofyear\n",
        "\n",
        "    feature_column = [col for col in df.columns if \"meanmodeldata\" in col or \"stdmodeldata\" in col or \"julean_day\" in col]\n",
        "    target_column = [col for col in df.columns if \"observeddata\" in col][0]  \n",
        "\n",
        "\n",
        "    # Split the data into training and testing sets (4-way split)\n",
        "\n",
        "    num_splits = 4\n",
        "    split_size = len(df) // num_splits\n",
        "   \n",
        "    sheet_average_metrics = []\n",
        "    all_results= []\n",
        "        \n",
        "    for split_num in range(num_splits):\n",
        "        start_index = split_num * split_size\n",
        "        end_index = (split_num + 1) * split_size\n",
        "\n",
        "        X = df[feature_column].values\n",
        "        Y = df[target_column].values\n",
        "\n",
        "        # Use indices to perform sequential split\n",
        "        X_train, X_test = np.concatenate([X[:start_index], X[end_index:]]), X[start_index:end_index]\n",
        "        Y_train, Y_test = np.concatenate([Y[:start_index], Y[end_index:]]), Y[start_index:end_index]\n",
        "\n",
        "        meanmodeldata_test = meanmodeldata[start_index:end_index]\n",
        "        observeddata_test = observeddata[start_index:end_index]\n",
        "        \n",
        "        print(meanmodeldata_test)\n",
        "        print(observeddata_test)\n",
        "\n",
        "        Date_test = df['Date'].values[start_index:end_index]\n",
        "        \n",
        "        # Reshaping the input for LSTM\n",
        "        X_train = X_train.reshape(X_train.shape[0], 1, 3)\n",
        "        X_test = X_test.reshape(X_test.shape[0], 1, 3)\n",
        "\n",
        "        print('length of X_test =', len(X_test))\n",
        "        print('length of X_train =', len(X_train))\n",
        "        print('length of Y_test =', len(Y_test))\n",
        "        print('length of Y_train =', len(Y_train))\n",
        "\n",
        "        print('sheet name', sheet_name, ':' , 'num_split', split_num, ': ',\"X_train\" , X_train  )\n",
        "        print('sheet name', sheet_name, ':' , 'num_split', split_num, ': ', \"X_test\",  X_test )\n",
        "\n",
        "        results, Y_pred= train_and_evaluate_model(X_train, Y_train, X_test, Y_test, sheet_name, split_num)\n",
        "        sheet_average_metrics.append(results)\n",
        "\n",
        "        \n",
        "        for i in range(len(Y_test)):\n",
        "                    all_results.append({\n",
        "                        'Sheet Name': sheet_name,\n",
        "                        'Split Number': split_num,\n",
        "                        'Date': Date_test[i],\n",
        "                        'Model_trained_observed_value': Y_pred[i],\n",
        "                        'observeddata_test': Y_test[i],\n",
        "                        'meanmodeldata_test' : meanmodeldata_test[i]\n",
        "                    })\n",
        "\n",
        "        #  metrics for the current split\n",
        "        print(f\"Results for {sheet_name} - Split {split_num+1}\")\n",
        "        for res in results:\n",
        "            print(f\"RMSE: {res['RMSE']:.4f}\")\n",
        "            print(f\"MSE: {res['MSE']:.4f}\")\n",
        "            print(f\"MAE: {res['MAE']:.4f}\")\n",
        "            print(f\"Bias: {res['Bias']:.4f}\")\n",
        "            print()\n",
        "\n",
        "    # To Calculate the average metrics for this sheet\n",
        "    # Initializing lists to store each metric separately\n",
        "    rmse_values = []\n",
        "    mse_values = []\n",
        "    mae_values = []\n",
        "    bias_values = []\n",
        "\n",
        "    for result in sheet_average_metrics:\n",
        "        for res in result:\n",
        "            rmse_values.append(res['RMSE'])\n",
        "            mse_values.append(res['MSE'])\n",
        "            mae_values.append(res['MAE'])\n",
        "            bias_values.append(res['Bias'])\n",
        "\n",
        "    # mean for each metric\n",
        "    average_rmse = np.mean(rmse_values)\n",
        "    average_mse = np.mean(mse_values)\n",
        "    average_mae = np.mean(mae_values)\n",
        "    average_bias = np.mean(bias_values)\n",
        "\n",
        "    # Average metrics for the current sheet\n",
        "    print(f\"Average Metrics for {sheet_name}:\")\n",
        "    print(f\"Average RMSE: {average_rmse:.4f}\")\n",
        "    print(f\"Average MSE: {average_mse:.4f}\")\n",
        "    print(f\"Average MAE: {average_mae:.4f}\")\n",
        "    print(f\"Average Bias: {average_bias:.4f}\")\n",
        "    print()\n",
        "\n",
        "    #Metrics for Raw Data\n",
        "    \n",
        "    mse_raw = np.mean((observeddata-meanmodeldata) ** 2)\n",
        "    rmse_raw = np.sqrt(mse_raw)\n",
        "    mae_raw = np.mean(np.abs(observeddata-meanmodeldata))\n",
        "    bias_raw = np.mean(observeddata-meanmodeldata)\n",
        "\n",
        "    print(f\"Metrics of Raw Data {sheet_name}:\")\n",
        "    print(f\"RMSE: {rmse_raw:.4f}\")\n",
        "    print(f\"MSE: {mse_raw:.4f}\")\n",
        "    print(f\"MAE: {mae_raw:.4f}\")\n",
        "    print(f\"Bias: {bias_raw:.4f}\")\n",
        "    print()\n",
        "\n",
        "    # Append the average metrics to the all_metrics list\n",
        "    all_metrics.append([sheet_name, average_rmse, average_mse, average_mae, average_bias,rmse_raw, mse_raw, mae_raw, bias_raw ])\n",
        "\n",
        "    # Write all metrics to a CSV file\n",
        "    output_file_path = os.path.join(output_directory, 'error.csv')\n",
        "    with open(output_file_path, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # Write the header row\n",
        "        writer.writerow(['Sheet Name', 'Average RMSE', 'Average MSE', 'Average MAE', 'Average Bias','rmse_raw', 'mse_raw', 'mae_raw', 'bias_raw'])\n",
        "        # Write the data rows\n",
        "        writer.writerows(all_metrics)\n",
        "\n",
        "    # Save all results to a single CSV file\n",
        "    result_file = os.path.join(output_directory, f'{sheet_name}.csv')\n",
        "    result_df = pd.DataFrame(all_results)\n",
        "    result_df.to_csv(result_file, index=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
